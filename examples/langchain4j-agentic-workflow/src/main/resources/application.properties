# ---- LangChain4j / Ollama ----
quarkus.langchain4j.ollama.chat-model.model-id=llama3.2
quarkus.langchain4j.ollama.base-url=http://localhost:11434
# Ask the model to be concise so dev UI calls are fast-ish
quarkus.langchain4j.ollama.chat-model.temperature=0.7
# ---- Quarkus Flow ----
# Optional, but nice to see logs when you hit workflows from Dev UI
quarkus.log.category."io.quarkiverse.flow".level=DEBUG
quarkus.langchain4j.log-responses=true
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.timeout=60000
