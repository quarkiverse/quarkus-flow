= Lab 4 – Agentic workflows with LangChain4j
:page-role: tutorial
include::../includes/attributes.adoc[]

In this lab you:

* Define LangChain4j agents as CDI beans.
* Orchestrate them with a Quarkus Flow workflow.
* Add a simple “draft → critique → approve” loop.

We’ll reuse the example classes under `{docs-repo}/org/acme/agentic`.

== 1. Add LangChain4j dependencies

Pick a backend (Ollama or OpenAI):

[source,xml]
----
<dependency>
  <groupId>io.quarkiverse.langchain4j</groupId>
  <artifactId>quarkus-langchain4j-ollama</artifactId>
</dependency>
<!-- or:
<dependency>
  <groupId>io.quarkiverse.langchain4j</groupId>
  <artifactId>quarkus-langchain4j-openai</artifactId>
</dependency>
-->
----

Configure the provider minimally (for example, Ollama):

[source,properties]
----
quarkus.langchain4j.ollama.base-url=http://localhost:11434
quarkus.langchain4j.ollama.chat-model.model=llama3.1
----

See xref:langchain4j.adoc[Agentic workflows with LangChain4j] for more options.

== 2. Define the agents

Create a drafter and a critic agent:

[source,java]
----
include::{examples-dir-level1}org/acme/agentic/DrafterAgent.java[tag=agent]
----

You can add a separate critic agent interface in the same style (or reuse the example one).

== 3. Create the agentic workflow

Compose the agents in a `Flow`:

[source,java]
----
include::{examples-dir-level1}org/acme/agentic/HelloAgenticWorkflow.java[tag=workflow]
----

This workflow typically:

. Reads a `seedPrompt` from the input data.
. Calls the drafter agent and exports the draft text.
. Calls the critic agent to review the draft.
. Decides whether to loop (if revisions are needed) or finish.

Use `inputFrom`, `exportAs`, and `outputAs` to keep the data shape clean.

== 4. Run and inspect

Start Quarkus in dev mode:

[source,shell]
----
./mvnw quarkus:dev
----

Call the agentic workflow via REST (for example, using a small resource that injects `HelloAgenticWorkflow`)
or directly from Dev UI if a Flow card is present.

Experiment with:

* Different `seedPrompt` values.
* Adding a simple “max revision rounds” counter in the workflow data.
* Logging the intermediate drafts to see how the loop behaves.

== 5. Human-in-the-loop (optional)

Extend the workflow by:

* Emitting a review-required event after the critic step.
* Listening for a “human review done” event to decide whether to loop or finalize.

You can reuse the Emit/Listen patterns from xref:messaging.adoc[Use messaging and events]
and the example shown in xref:langchain4j.adoc[Agentic workflows with LangChain4j].

== 6. What you learned

* How to wire LangChain4j AI services into workflows.
* How to structure agent calls as tasks with clear input/output contracts.
* How to implement simple agentic loops and optionally add human-in-the-loop steps.
